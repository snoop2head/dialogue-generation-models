{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "use_chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOyHYrbpb8NnpuA7y/n6x4k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snoop2head/dialogue-generation-models/blob/master/use_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esfnzq5tflb4",
        "outputId": "69b7dd1c-a4d1-49ff-bdca-77b73f7272ad"
      },
      "source": [
        "\"\"\"cloning dialogue generation models running code\"\"\"\n",
        "!git clone https://github.com/snoop2head/dialogue-generation-models"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'dialogue-generation-models'...\n",
            "remote: Enumerating objects: 227, done.\u001b[K\n",
            "remote: Counting objects: 100% (227/227), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 227 (delta 118), reused 157 (delta 73), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (227/227), 1.12 MiB | 12.44 MiB/s, done.\n",
            "Resolving deltas: 100% (118/118), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR38JHjMhIJQ",
        "outputId": "07f1fc16-6fd6-4c45-fdbe-dd0f9a4c73d4"
      },
      "source": [
        "\"\"\"Installing pretrained Language Models from Google Drive\"\"\"\n",
        "# Estimated Execution Time: 4 mins 30 seconds\n",
        "\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Choose a local colab directory to store the data.\n",
        "PATH = \"./dialogue-generation-models/models\"\n",
        "local_download_path = os.path.expanduser(PATH)\n",
        "try:\n",
        "  os.makedirs(local_download_path)\n",
        "except: pass\n",
        "\n",
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "file_list = drive.ListFile(\n",
        "    {'q': \"'1HCbvJllHr5eGxFQ69sn3Fb2nM2vrJeKs' in parents\"}).GetList() # query of the google drive directory\n",
        "\n",
        "for f in file_list:\n",
        "  # 3. Create & download by id.\n",
        "  print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "  fname = os.path.join(local_download_path, f['title'])\n",
        "  print('downloading to {}'.format(fname))\n",
        "  f_ = drive.CreateFile({'id': f['id']})\n",
        "  f_.GetContentFile(fname)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "title: large_meena_trained_on_filtered_data_kr.pth, id: 13RDDqb5jlIEpgbFkPgVRQBwZm_Kbfuqe\n",
            "downloading to ./dialogue-generation-models/models/large_meena_trained_on_filtered_data_kr.pth\n",
            "title: large_gpt_trained_on_wiki_and_dialogue_data_kr.pth, id: 1fTUozDYsgr2yIaV6AJBB7iGf-Ill8MtT\n",
            "downloading to ./dialogue-generation-models/models/large_gpt_trained_on_wiki_and_dialogue_data_kr.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJqzWQ31kk09",
        "outputId": "b7350a2a-c40d-499f-baf5-f715fcdf60ac"
      },
      "source": [
        "# Get current working directory\n",
        "import os\n",
        "cwd = os.getcwd()\n",
        "print(\"current working directory:\",cwd)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "current working directory: /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OfIMnmWjlI-z",
        "outputId": "2363573c-690d-4983-900b-40e3cad5d1f5"
      },
      "source": [
        "# switch directory into forked github repository\n",
        "%cd dialogue-generation-models/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/dialogue-generation-models\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVn7x3DGlMKh",
        "outputId": "37e70c6c-cb82-42a6-d86b-f343cc821600"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "configs\t\t\t    pyproject.toml\t  run_gpt.py\ttokenizer\n",
            "dialogue_generation_models  README.md\t\t  run_meena.py\n",
            "LICENSE\t\t\t    requirements-dev.txt  setup.cfg\n",
            "models\t\t\t    requirements.txt\t  setup.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud_F3j0dmAqR",
        "outputId": "afbab1e2-1da2-4df9-d9f9-eb9f180e102a"
      },
      "source": [
        "# install requirements\n",
        "# Execution time: 3 min\n",
        "!pip install -r requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 21kB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/e2/813dff3d72df2f49554204e7e5f73a3dc0f0eb1e3958a4cad3ef3fb278b7/sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 23.0MB/s \n",
            "\u001b[?25hCollecting transformers==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 27.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 3)) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 3)) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 3)) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/26/c02ba92ecb8b780bdae4a862d351433c2912fe49469dac7f87a5c85ccca6/tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 30.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.1.0->-r requirements.txt (line 3)) (20.9)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0->-r requirements.txt (line 3)) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.1.0->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.1.0->-r requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0->-r requirements.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.1.0->-r requirements.txt (line 3)) (1.15.0)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, sentencepiece, tokenizers, sacremoses, transformers\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed sacremoses-0.0.45 sentencepiece-0.1.91 tokenizers-0.8.1rc2 torch-1.6.0 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u08UHvvhivi",
        "outputId": "f92b35ba-03bf-402b-80a6-4311358cd01e"
      },
      "source": [
        "# Running Script for sample dialogue\n",
        "# Input [\"최근에 영화 본 거 있어?\", \"기생충 봤는데 엄청 재밌더라\", \"오 그래? 다들 재밌다고 하더라\", \"아직 못봤어?\", \"응 나도 봐야하나..\"],\n",
        "!python run_meena.py \\\n",
        "--pretrained-model-path /content/dialogue-generation-models/models/large_meena_trained_on_filtered_data_kr.pth \\\n",
        "        --model-config-path /content/dialogue-generation-models/configs/large_meena_config.json \\\n",
        "        --tokenizer-model-path /content/dialogue-generation-models/tokenizer/kr_spm.model \\\n",
        "        --decoding-method top_p"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 14:00:10.073343: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "normalizer.cc(50) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 아니 최근에 본건 없는데\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 최근에 본거? 없는뎅...\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 아니.. 너는? 난 최근에 뭐 봤는지 몰라서\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 그거 본거 같은데..!\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 음.. 아니.. 딱히 없는뎅...\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 최근에...? 딱히 본게 없는거같앙\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 영화관가면 맨날 영화만 봤는데ㅋㅋ\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 1987이랑 인크레더블! 근데 너무 잔인해서 안봤어...\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 음... 그시절 우리가 좋아했던 소녀!\n",
            "Context: 최근에 영화 본 거 있어? \t Reply: 그거 세개!! 12년도에 본건 없는거 같아용\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 아 그거 내가 본건데\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: ㅋㅋㅋㅋㅋ 난 아직 안봤어\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 그거 엄청 재밌다던데~ ㅋㅋㅋ\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 기생충? 그게 뭐징...\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 그거 예고편 봤는데 엄청 슬프던데?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 그거 영화 내용이 뭐야?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 아 맞아 기생충! 진짜 재밌더라\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 아 그거 봤구나~ 기생충도 재밌게 본 영화였는데!\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: 기생충 봤는데 또 보는 거야?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 \t Reply: ㅋㅋㅋㅋㅋ 나도 그거 봄\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 응응 엄청 재밌던데ㅋㅋ 그거 다 보고 싶은데 시간이 안난다\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 재밌어 근데 좀 잔인하더라\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 영화관에서 혼자 봤어?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: ㅋㅋㅋㅋ 너도 봤어?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 12세 관람가라서 다들 잘 챙겨보더라\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 너 그거 봤어? 그..검은사제들\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 맞아 영화관에서 볼 때도 재밌었어\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 응응 너도 봐봐 꿀잼\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 그치! 영화보는 내내 웃었어ㅋㅋ\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 \t Reply: 근데 2편이 좀 더 재밌다\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 아니 다 봤지ㅋㅋ 재밌다던데\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 그거 한번 더 보려고!\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 웅 못봤어 재밌다고 해서\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 응.. 나중에 같이 보자!\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 아직 안봤지~ 다음에 봐야지\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 응.. 내가 봤을 때는 아직 상영하더라고\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 봤는데 기억이 잘 안나네\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 웅 안봤어ㅋㅋㅋㅋ 기생충 볼까?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 응ㅋㅋ 아직 안 봤어!\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? \t Reply: 응 지금은 바빠서..ㅋㅋ\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 지금 3.0에 있던데\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 기생충 재밌는데?ㅋㅋㅋ 너도 보고싶으면 같이 보자!\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 보러갈까? ㅎㅎ 너도 볼래?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 나 12월에 또 보러갈까 생각중\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 재밌어 진짜 ㅋㅋ 1편부터 보자\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 보러가자 같이 보자 ㅎㅎ 나 오늘 늦게 잘거야\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 요즘 영화는 재밌는거 좀 많던데?\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 나도 아직 못봤는데... 재밌다고 하더라\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 내가 보여줄게ㅋㅋ 근데 기생충은 진짜 재밌어\n",
            "Context: 최근에 영화 본 거 있어? [SEPT] 기생충 봤는데 엄청 재밌더라 [SEPT] 오 그래? 다들 재밌다고 하더라 [SEPT] 아직 못봤어? [SEPT] 응 나도 봐야하나.. \t Reply: 시간될때 봐ㅋㅋ 아 근데\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hs8fmGO3lfrz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}